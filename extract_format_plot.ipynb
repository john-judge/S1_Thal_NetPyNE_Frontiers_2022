{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import subprocess\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "# pickle\n",
    "import pickle\n",
    "\n",
    "from src.hVOS.cell import Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 1\n",
    "\n",
    "data_dir = 'C:/Users/jjudge3/Desktop/neuron docker/'\n",
    "compart_data = {}\n",
    "should_create_mem_map = False  # if True, create mem mapped files. If False, load mem mapped files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apic_0_10': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/apic_0_10/',\n",
       " 'apic_100_140': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/apic_100_140/',\n",
       " 'apic_10_20': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/apic_10_20/',\n",
       " 'apic_140_180': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/apic_140_180/',\n",
       " 'apic_20_30': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/apic_20_30/',\n",
       " 'apic_30_40': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/apic_30_40/',\n",
       " 'apic_40_60': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/apic_40_60/',\n",
       " 'apic_60_80': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/apic_60_80/',\n",
       " 'apic_80_100': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/apic_80_100/',\n",
       " 'axon_0_10': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/axon_0_10/',\n",
       " 'dend_0_10': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/dend_0_10/',\n",
       " 'dend_100_140': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/dend_100_140/',\n",
       " 'dend_10_20': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/dend_10_20/',\n",
       " 'dend_140_180': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/dend_140_180/',\n",
       " 'dend_180_220': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/dend_180_220/',\n",
       " 'dend_20_30': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/dend_20_30/',\n",
       " 'dend_30_40': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/dend_30_40/',\n",
       " 'dend_40_60': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/dend_40_60/',\n",
       " 'dend_60_80': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/dend_60_80/',\n",
       " 'dend_80_100': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/dend_80_100/',\n",
       " 'soma': 'C:/Users/jjudge3/Desktop/neuron docker/archive/run1/soma/'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all the .tar.gz files\n",
    "\n",
    "target_dir = data_dir + 'archive/run' + str(run_id) + \"/\"\n",
    "for file in os.listdir(data_dir):\n",
    "    compart = file.replace('.tar.gz', \"\").replace('S1-Thal-output-',\"\")\n",
    "    output_dir = target_dir + compart + '/'\n",
    "    \n",
    "    if file.endswith('.tar.gz'):\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            result = subprocess.run(['tar', '-xzvf', data_dir + file, \"-C\", output_dir], capture_output=True, text=True, check=True)\n",
    "            \n",
    "            print('Extracted ' + file)\n",
    "        # else it already exists and was extracted\n",
    "        #os.rename(data_dir + file, data_dir + 'archive/' + file)\n",
    "        compart_data[compart] = output_dir\n",
    "compart_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['netpyne_version', 'netpyne_changeset', 'net', 'simConfig', 'simData'])\n"
     ]
    }
   ],
   "source": [
    "# load one pkl to look at cell data\n",
    "cell_id_to_me_type_map = {}\n",
    "\n",
    "# \n",
    "me_type_map_file = 'C:/Users/jjudge3/Desktop/neuron docker/' + 'archive/run' + str(run_id) + \"/\" + 'cell_id_to_me_type_map.pkl'\n",
    "\n",
    "if os.path.exists(me_type_map_file):\n",
    "    with open(me_type_map_file, 'rb') as f:\n",
    "        cell_id_to_me_type_map = pickle.load(f)\n",
    "else:\n",
    "\n",
    "    compart = list(compart_data.keys())[0]\n",
    "    target_dir_net = compart_data[compart] + '/S1_Thal_NetPyNE_Frontiers_2022/data/v7_batch1/v7_batch1_0_0_data.pkl'\n",
    "\n",
    "    with open(target_dir_net, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        print(data.keys())\n",
    "        for cell_dict in data['net']['cells']:\n",
    "            cell_id_to_me_type_map[cell_dict['gid']] = {\n",
    "                'me_type': cell_dict['tags']['cellType'],\n",
    "                'x': cell_dict['tags']['x'],\n",
    "                'y': cell_dict['tags']['y'],\n",
    "                'z': cell_dict['tags']['z']\n",
    "            }\n",
    "\n",
    "    with open(me_type_map_file, 'wb') as f:\n",
    "        pickle.dump(cell_id_to_me_type_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_compart_data = {}\n",
    "time = None\n",
    "if should_create_mem_map:\n",
    "    for compart in compart_data.keys():\n",
    "        print(compart)\n",
    "        if compart in loaded_compart_data:\n",
    "            continue\n",
    "        target_dir = compart_data[compart]\n",
    "        if not os.path.exists(target_dir):\n",
    "            print('Directory ' + target_dir + ' does not exist')\n",
    "            continue\n",
    "        target_dir += '/S1_Thal_NetPyNE_Frontiers_2022/data/v7_batch1/'\n",
    "        data_file = target_dir + 'v7_batch1_0_0_data.pkl'\n",
    "\n",
    "        if not os.path.exists(data_file):\n",
    "            print(\"Data file not found:\", data_file)\n",
    "            continue\n",
    "        # also skip if the .dat files already exist\n",
    "        mmaps_exist = False\n",
    "        for file in os.listdir(target_dir):\n",
    "            if file.endswith('.dat') and 'v7_batch1_0_0' in file and 'cell' in file:\n",
    "                print(\"\\t\", target_dir + file)\n",
    "                mmaps_exist = True\n",
    "                break\n",
    "        if mmaps_exist:\n",
    "            print(\"Memory mapped files already exist for compartment\", compart)\n",
    "            continue\n",
    "\n",
    "        # Load data\n",
    "        with open(data_file, 'rb') as f:\n",
    "            try:\n",
    "                data = pickle.load(f)\n",
    "            except MemoryError:\n",
    "                print(\"MemoryError with file:\", data_file)\n",
    "                raise MemoryError\n",
    "            print(data.keys())\n",
    "            if time is None:  # store t only once\n",
    "                time = np.array(data['simData']['t'])\n",
    "\n",
    "            for k in data['simData']:\n",
    "                if compart[:4] in k:\n",
    "                    for cell_id in data['simData'][k]:\n",
    "                        print(k, cell_id)\n",
    "\n",
    "                        # create memory mapped file for this cell's segment data\n",
    "                        mm_data_fp = target_dir + 'v7_batch1_0_0_' + k + '_' + cell_id + '.dat'\n",
    "                        cell_data = np.array(data['simData'][k][cell_id])\n",
    "\n",
    "                        # create empty file if it doesn't exist\n",
    "                        if not os.path.exists(mm_data_fp):\n",
    "                            with open(mm_data_fp, 'wb') as f:\n",
    "                                f.write(b'\\0' * cell_data.nbytes)\n",
    "\n",
    "                        # store as a memory mapped array for faster access / less memory usage\n",
    "                        mm_data_fp = np.memmap(mm_data_fp, dtype='float32', mode='w+', shape=cell_data.shape)\n",
    "                        mm_data_fp[:] = cell_data[:]\n",
    "                        mm_data_fp.flush()\n",
    "                        if compart not in loaded_compart_data:\n",
    "                            loaded_compart_data[compart] = {}\n",
    "                        if cell_id not in loaded_compart_data[compart]:\n",
    "                            loaded_compart_data[compart][cell_id] = {}\n",
    "                        loaded_compart_data[compart][cell_id] = mm_data_fp  # store just pointer\n",
    "            # to avoid memory issues, delete data after it's been stored\n",
    "            del data\n",
    "            gc.collect()\n",
    "\n",
    "    # also store time to memory mapped file\n",
    "    if time is not None:\n",
    "        target_dir = data_dir + 'archive/run' + str(run_id) + '/'\n",
    "        mm_time_fp = target_dir + 'v7_batch1_0_0_time.dat'\n",
    "        if not os.path.exists(mm_time_fp):\n",
    "            with open(mm_time_fp, 'wb') as f:\n",
    "                f.write(b'\\0' * time.nbytes)\n",
    "        mm_time_fp = np.memmap(mm_time_fp, dtype='float32', mode='w+', shape=time.shape)\n",
    "        mm_time_fp[:] = time[:]\n",
    "        mm_time_fp.flush()\n",
    "        loaded_compart_data['time'] = mm_time_fp  # store just pointer\n",
    "else: # load mem mapped files. Get file pointers from looking through data_dir dat files and load them into loaded_compart_data\n",
    "    for compart in compart_data.keys(): \n",
    "        target_dir = data_dir + 'archive/run' + str(run_id) + '/' + compart\n",
    "        if not os.path.exists(target_dir):\n",
    "            print('Directory ' + target_dir + ' does not exist')\n",
    "            continue\n",
    "        target_dir += '/S1_Thal_NetPyNE_Frontiers_2022/data/v7_batch1/'\n",
    "        for file in os.listdir(target_dir):\n",
    "            if file.endswith('.dat') and 'v7_batch1_0_0' in file and 'cell' in file:\n",
    "                file_name = file.replace(\".dat\", \"\").replace(\"v7_batch1_0_0_\", \"\").split('_')\n",
    "                compart = \"_\".join(file_name[:2])\n",
    "                cell_id = \"_\".join(file_name[2:])\n",
    "                if 'soma' in file:\n",
    "                    compart = 'Vsoma'\n",
    "                    cell_id = 'cell_' + cell_id\n",
    "                    \n",
    "                if compart not in loaded_compart_data:\n",
    "                    loaded_compart_data[compart] = {}\n",
    "                if cell_id not in loaded_compart_data[compart]:\n",
    "                    loaded_compart_data[compart][cell_id] = {}\n",
    "                loaded_compart_data[compart][cell_id] = target_dir + file\n",
    "    # load time\n",
    "    target_dir = data_dir + 'archive/run' + str(run_id) + '/'\n",
    "    mm_time_fp = target_dir + 'v7_batch1_0_0_time.dat'\n",
    "    loaded_compart_data['time'] = np.memmap(mm_time_fp, dtype='float32', mode='r')\n",
    "\n",
    "loaded_compart_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each soma, get a cell id and aggregate its axons, apics, dends\n",
    "cells = {}\n",
    "for cell_id in loaded_compart_data['Vsoma']:\n",
    "    soma = loaded_compart_data['Vsoma'][cell_id]\n",
    "    axons = {}\n",
    "    apics = {}\n",
    "    dends = {}\n",
    "    for compart in loaded_compart_data.keys():\n",
    "        if compart == 'time':\n",
    "            continue\n",
    "        if cell_id in loaded_compart_data[compart]:\n",
    "            if 'axon' in compart:\n",
    "                axons[compart] = loaded_compart_data[compart][cell_id]\n",
    "            elif 'apic' in compart:\n",
    "                apics[compart] = loaded_compart_data[compart][cell_id]\n",
    "            elif 'dend' in compart:\n",
    "                dends[compart] = loaded_compart_data[compart][cell_id]\n",
    "    cells[cell_id] = Cell(cell_id, None, None, axons, apics, dends, soma)\n",
    "\n",
    "cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a random cell to plot\n",
    "rand_cell_id = 'cell_21986' #np.random.choice(list(cells.keys()))\n",
    "rand_cell = cells[rand_cell_id]\n",
    "\n",
    "apics = rand_cell.get_apic_filemap()\n",
    "dends = rand_cell.get_dend_filemap()\n",
    "axons = rand_cell.get_axon_filemap()\n",
    "time = loaded_compart_data['time']\n",
    "\n",
    "# plot trace for cell \n",
    "plt.figure()\n",
    "\n",
    "handles = [None, None, None, None]\n",
    "for apic_comp in apics:\n",
    "    handles[1] = plt.plot(time, rand_cell.get_voltage_trace(compart_id=apic_comp),  c='r', alpha=0.5)\n",
    "for dend_comp in dends:\n",
    "    handles[2] = plt.plot(time, rand_cell.get_voltage_trace(compart_id=dend_comp),  c='g', alpha=0.5)\n",
    "for axon_comp in axons:\n",
    "    handles[3] = plt.plot(time, rand_cell.get_voltage_trace(compart_id=axon_comp),  c='b', alpha=0.5)\n",
    "handles[0] = plt.plot(time, rand_cell.get_soma_voltage_trace(), c='k', linewidth=2)\n",
    "\n",
    "labels = ['Soma', 'Apic', 'Dend', 'Axon']\n",
    "labels = [labels[i] for i in range(len(handles)) if handles[i] is not None]\n",
    "handles = [h[0] for h in handles if h is not None]\n",
    "\n",
    "plt.legend(handles=handles, labels=['Soma', 'Apic', 'Dend', 'Axon'])\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Voltage (mV)')\n",
    "plt.title('Compartment Voltages for ' + rand_cell_id)\n",
    "plt.savefig('comp_voltage_' + rand_cell_id + '.png')\n",
    "print(os.getcwd() + 'comp_voltage_' + rand_cell_id + '.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spkt = data['simData']['spkt']\n",
    "spkid = data['simData']['spkid']\n",
    "Vapic_0 = data['simData']['Vapic_0']\n",
    "print('spkt:', spkt)\n",
    "print('spkid:', spkid)\n",
    "print('Vapic_0:', Vapic_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_traces = 0\n",
    "for k in data['simData'].keys():\n",
    "    if k.startswith(\"V\") and \"_\" in k:\n",
    "        #print(k)\n",
    "        #print(\"\\t\", len(data['simData'][k]))\n",
    "        n_traces += len(data['simData'][k])\n",
    "print(\"n_traces:\", n_traces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TSM-to-ZDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
